[2017-08-22 00:16:05,017][DEBUG][action.admin.indices.mapping.put] [Air-Walker] failed to put mappings on indices [[guruin_dev]], type [feeds]
MapperParsingException[Root mapping definition has unsupported parameters:  [created_at : {type=data}]]
	at org.elasticsearch.index.mapper.DocumentMapperParser.checkNoRemainingFields(DocumentMapperParser.java:267)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:255)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:382)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:16:05,031][INFO ][rest.suppressed          ] /guruin_dev/_mapping/feeds Params: {index=guruin_dev, type=feeds}
MapperParsingException[Root mapping definition has unsupported parameters:  [created_at : {type=data}]]
	at org.elasticsearch.index.mapper.DocumentMapperParser.checkNoRemainingFields(DocumentMapperParser.java:267)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:255)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:382)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:18:42,343][DEBUG][action.admin.indices.mapping.put] [Air-Walker] failed to put mappings on indices [[guruin_dev]], type [feeds]
MapperParsingException[No handler for type [data] declared on field [created_at]]
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:313)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:382)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:18:42,343][INFO ][rest.suppressed          ] /guruin_dev/_mapping/feeds Params: {index=guruin_dev, type=feeds}
MapperParsingException[No handler for type [data] declared on field [created_at]]
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:313)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:382)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:19:31,648][DEBUG][action.admin.indices.mapping.put] [Air-Walker] failed to put mappings on indices [[guruin_dev]], type [feeds]
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [string]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:19:31,649][INFO ][rest.suppressed          ] /guruin_dev/_mapping/feeds Params: {index=guruin_dev, type=feeds}
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [string]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:25:01,230][DEBUG][action.admin.indices.mapping.put] [Air-Walker] failed to put mappings on indices [[guruin_dev]], type [feeds]
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [date]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:25:01,230][INFO ][rest.suppressed          ] /guruin_dev/_mapping/feeds Params: {index=guruin_dev, type=feeds}
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [date]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:25:24,993][DEBUG][action.admin.indices.mapping.put] [Air-Walker] failed to put mappings on indices [[guruin_dev]], type [feeds]
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [date]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 00:25:24,993][INFO ][rest.suppressed          ] /guruin_dev/_mapping/feeds Params: {index=guruin_dev, type=feeds}
MergeMappingException[Merge failed with failures {[mapper [created_at] of different type, current_type [long], merged_type [date]]}]
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$2.execute(MetaDataMappingService.java:388)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 10:47:37,083][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
ElasticsearchParseException[failed to parse source for create index]; nested: JsonParseException[Unexpected character ('}' (code 125)): was expecting either valid name character (for unquoted name) or double-quote (for quoted) to start field name
 at [Source: org.elasticsearch.transport.netty.ChannelBufferStreamInput@d133ea6; line: 1, column: 56411]];
	at org.elasticsearch.action.admin.indices.create.CreateIndexRequest.source(CreateIndexRequest.java:370)
	at org.elasticsearch.rest.action.admin.indices.create.RestCreateIndexAction.handleRequest(RestCreateIndexAction.java:47)
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54)
	at org.elasticsearch.rest.RestController.executeHandler(RestController.java:207)
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:166)
	at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:128)
	at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:86)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:348)
	at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:63)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:194)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:135)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:452)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('}' (code 125)): was expecting either valid name character (for unquoted name) or double-quote (for quoted) to start field name
 at [Source: org.elasticsearch.transport.netty.ChannelBufferStreamInput@d133ea6; line: 1, column: 56411]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1487)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:518)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:447)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleOddName(UTF8StreamJsonParser.java:1928)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseName(UTF8StreamJsonParser.java:1617)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:700)
	at org.elasticsearch.common.xcontent.json.JsonXContentParser.nextToken(JsonXContentParser.java:53)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:269)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:245)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.map(AbstractXContentParser.java:208)
	at org.elasticsearch.action.admin.indices.create.CreateIndexRequest.source(CreateIndexRequest.java:368)
	... 46 more
[2017-08-22 10:50:09,494][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
[guruin_dev] IndexAlreadyExistsException[already exists]
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:161)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:512)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:90)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:231)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 10:52:02,687][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
ElasticsearchParseException[failed to parse source for create index]; nested: JsonParseException[Unexpected character ('}' (code 125)): was expecting either valid name character (for unquoted name) or double-quote (for quoted) to start field name
 at [Source: org.elasticsearch.transport.netty.ChannelBufferStreamInput@51956705; line: 994, column: 12]];
	at org.elasticsearch.action.admin.indices.create.CreateIndexRequest.source(CreateIndexRequest.java:370)
	at org.elasticsearch.rest.action.admin.indices.create.RestCreateIndexAction.handleRequest(RestCreateIndexAction.java:47)
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54)
	at org.elasticsearch.rest.RestController.executeHandler(RestController.java:207)
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:166)
	at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:128)
	at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:86)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:348)
	at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:63)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:194)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:135)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:452)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('}' (code 125)): was expecting either valid name character (for unquoted name) or double-quote (for quoted) to start field name
 at [Source: org.elasticsearch.transport.netty.ChannelBufferStreamInput@51956705; line: 994, column: 12]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1487)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:518)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:447)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleOddName(UTF8StreamJsonParser.java:1928)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseName(UTF8StreamJsonParser.java:1617)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:700)
	at org.elasticsearch.common.xcontent.json.JsonXContentParser.nextToken(JsonXContentParser.java:53)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:269)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readValue(AbstractXContentParser.java:314)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:274)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.readMap(AbstractXContentParser.java:245)
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.map(AbstractXContentParser.java:208)
	at org.elasticsearch.action.admin.indices.create.CreateIndexRequest.source(CreateIndexRequest.java:368)
	... 46 more
[2017-08-22 10:52:19,974][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
[guruin_dev] IndexAlreadyExistsException[already exists]
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:161)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:512)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:90)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:231)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2017-08-22 10:52:35,997][INFO ][cluster.metadata         ] [Air-Walker] [guruin_dev] deleting index
[2017-08-22 10:52:44,442][DEBUG][action.admin.indices.create] [Air-Walker] [guruin_dev] failed to create
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:266)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 10:52:44,443][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:266)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 10:52:58,162][INFO ][node                     ] [Air-Walker] stopping ...
[2017-08-22 10:52:58,191][INFO ][node                     ] [Air-Walker] stopped
[2017-08-22 10:52:58,191][INFO ][node                     ] [Air-Walker] closing ...
[2017-08-22 10:52:58,201][INFO ][node                     ] [Air-Walker] closed
[2017-08-22 11:02:53,948][INFO ][node                     ] [Meathook] version[2.0.0], pid[19045], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:02:53,948][INFO ][node                     ] [Meathook] initializing ...
[2017-08-22 11:02:53,955][ERROR][bootstrap                ] Exception
java.lang.IllegalStateException: Unable to initialize plugins
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:115)
	at org.elasticsearch.node.Node.<init>(Node.java:144)
	at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:145)
	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:270)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.nio.file.NoSuchFileException: /Users/luotao/Downloads/elasticsearch-2.0.0/plugins/ik/plugin-descriptor.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:86)
	at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:306)
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:112)
	... 5 more
[2017-08-22 11:12:07,329][INFO ][node                     ] [Big Man] version[2.0.0], pid[19796], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:12:07,330][INFO ][node                     ] [Big Man] initializing ...
[2017-08-22 11:12:07,334][ERROR][bootstrap                ] Exception
java.lang.IllegalStateException: Unable to initialize plugins
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:115)
	at org.elasticsearch.node.Node.<init>(Node.java:144)
	at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:145)
	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:270)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.nio.file.NoSuchFileException: /Users/luotao/Downloads/elasticsearch-2.0.0/plugins/ik/plugin-descriptor.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:86)
	at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:306)
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:112)
	... 5 more
[2017-08-22 11:14:17,561][INFO ][node                     ] [Buzz] version[2.0.0], pid[19919], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:14:17,561][INFO ][node                     ] [Buzz] initializing ...
[2017-08-22 11:14:17,822][INFO ][plugins                  ] [Buzz] loaded [analysis-ik], sites []
[2017-08-22 11:14:17,870][INFO ][env                      ] [Buzz] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:14:19,628][INFO ][node                     ] [Buzz] initialized
[2017-08-22 11:14:19,628][INFO ][node                     ] [Buzz] starting ...
[2017-08-22 11:14:19,720][INFO ][transport                ] [Buzz] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:14:19,727][INFO ][discovery                ] [Buzz] elasticsearch/pc4e9AIlQeifW7yTPv-KXA
[2017-08-22 11:14:22,766][INFO ][cluster.service          ] [Buzz] new_master {Buzz}{pc4e9AIlQeifW7yTPv-KXA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:14:22,792][INFO ][http                     ] [Buzz] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:14:22,792][INFO ][node                     ] [Buzz] started
[2017-08-22 11:14:22,799][INFO ][gateway                  ] [Buzz] recovered [0] indices into cluster_state
[2017-08-22 11:14:30,539][DEBUG][action.admin.indices.create] [Buzz] [guruin_dev] failed to create
[guruin_dev] IndexCreationException[failed to create index]; nested: IllegalArgumentException[Unknown Analyzer type [org.elasticsearch.index.analysis.IkAnalyzerProvider] for [ik]];
	at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:347)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:348)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown Analyzer type [org.elasticsearch.index.analysis.IkAnalyzerProvider] for [ik]
	at org.elasticsearch.index.analysis.AnalysisModule.configure(AnalysisModule.java:323)
	at org.elasticsearch.common.inject.AbstractModule.configure(AbstractModule.java:61)
	at org.elasticsearch.common.inject.spi.Elements$RecordingBinder.install(Elements.java:212)
	at org.elasticsearch.common.inject.spi.Elements.getElements(Elements.java:84)
	at org.elasticsearch.common.inject.InjectorShell$Builder.build(InjectorShell.java:130)
	at org.elasticsearch.common.inject.InjectorBuilder.build(InjectorBuilder.java:99)
	at org.elasticsearch.common.inject.InjectorImpl.createChildInjector(InjectorImpl.java:137)
	at org.elasticsearch.common.inject.ModulesBuilder.createChildInjector(ModulesBuilder.java:56)
	at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:343)
	... 7 more
[2017-08-22 11:14:30,542][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
[guruin_dev] IndexCreationException[failed to create index]; nested: IllegalArgumentException[Unknown Analyzer type [org.elasticsearch.index.analysis.IkAnalyzerProvider] for [ik]];
	at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:347)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:348)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown Analyzer type [org.elasticsearch.index.analysis.IkAnalyzerProvider] for [ik]
	at org.elasticsearch.index.analysis.AnalysisModule.configure(AnalysisModule.java:323)
	at org.elasticsearch.common.inject.AbstractModule.configure(AbstractModule.java:61)
	at org.elasticsearch.common.inject.spi.Elements$RecordingBinder.install(Elements.java:212)
	at org.elasticsearch.common.inject.spi.Elements.getElements(Elements.java:84)
	at org.elasticsearch.common.inject.InjectorShell$Builder.build(InjectorShell.java:130)
	at org.elasticsearch.common.inject.InjectorBuilder.build(InjectorBuilder.java:99)
	at org.elasticsearch.common.inject.InjectorImpl.createChildInjector(InjectorImpl.java:137)
	at org.elasticsearch.common.inject.ModulesBuilder.createChildInjector(ModulesBuilder.java:56)
	at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:343)
	... 7 more
[2017-08-22 11:14:41,596][INFO ][node                     ] [Buzz] stopping ...
[2017-08-22 11:14:41,607][INFO ][node                     ] [Buzz] stopped
[2017-08-22 11:14:41,607][INFO ][node                     ] [Buzz] closing ...
[2017-08-22 11:14:41,610][INFO ][node                     ] [Buzz] closed
[2017-08-22 11:15:15,967][INFO ][node                     ] [Sunstreak] version[2.0.0], pid[20061], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:15:15,967][INFO ][node                     ] [Sunstreak] initializing ...
[2017-08-22 11:15:16,125][INFO ][plugins                  ] [Sunstreak] loaded [analysis-ik], sites []
[2017-08-22 11:15:16,150][INFO ][env                      ] [Sunstreak] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:15:17,382][INFO ][node                     ] [Sunstreak] initialized
[2017-08-22 11:15:17,382][INFO ][node                     ] [Sunstreak] starting ...
[2017-08-22 11:15:17,468][INFO ][transport                ] [Sunstreak] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:15:17,475][INFO ][discovery                ] [Sunstreak] elasticsearch/wn5fHNKnSEuHmeUmkS7qqg
[2017-08-22 11:15:20,502][INFO ][cluster.service          ] [Sunstreak] new_master {Sunstreak}{wn5fHNKnSEuHmeUmkS7qqg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:15:20,520][INFO ][http                     ] [Sunstreak] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:15:20,521][INFO ][node                     ] [Sunstreak] started
[2017-08-22 11:15:20,533][INFO ][gateway                  ] [Sunstreak] recovered [0] indices into cluster_state
[2017-08-22 11:15:26,077][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 11:15:26,077][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 11:15:26,080][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 11:15:26,162][DEBUG][action.admin.indices.create] [Sunstreak] [guruin_dev] failed to create
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:15:26,165][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:16:51,487][INFO ][node                     ] [Sunstreak] stopping ...
[2017-08-22 11:16:51,498][INFO ][node                     ] [Sunstreak] stopped
[2017-08-22 11:16:51,498][INFO ][node                     ] [Sunstreak] closing ...
[2017-08-22 11:16:51,501][INFO ][node                     ] [Sunstreak] closed
[2017-08-22 11:22:52,027][INFO ][node                     ] [Princess Python] version[2.0.0], pid[20660], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:22:52,028][INFO ][node                     ] [Princess Python] initializing ...
[2017-08-22 11:22:52,036][ERROR][bootstrap                ] Exception
java.lang.IllegalStateException: Unable to initialize plugins
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:115)
	at org.elasticsearch.node.Node.<init>(Node.java:144)
	at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:145)
	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:270)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.nio.file.NoSuchFileException: /Users/luotao/Downloads/elasticsearch-2.0.0/plugins/pinyin/plugin-descriptor.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:86)
	at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:306)
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:112)
	... 5 more
[2017-08-22 11:23:34,495][INFO ][node                     ] [Odin] version[2.0.0], pid[20822], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:23:34,496][INFO ][node                     ] [Odin] initializing ...
[2017-08-22 11:23:34,561][ERROR][bootstrap                ] Exception
java.lang.IllegalArgumentException: Plugin [analysis-pinyin] is incompatible with Elasticsearch [2.0.0]. Was designed for version [5.5.1]
	at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:117)
	at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:306)
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:112)
	at org.elasticsearch.node.Node.<init>(Node.java:144)
	at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:145)
	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:270)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
[2017-08-22 11:25:27,512][INFO ][node                     ] [Goblin Queen] version[2.0.0], pid[21382], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:25:27,513][INFO ][node                     ] [Goblin Queen] initializing ...
[2017-08-22 11:25:27,671][INFO ][plugins                  ] [Goblin Queen] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 11:25:27,696][INFO ][env                      ] [Goblin Queen] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:25:28,903][INFO ][node                     ] [Goblin Queen] initialized
[2017-08-22 11:25:28,903][INFO ][node                     ] [Goblin Queen] starting ...
[2017-08-22 11:25:28,993][INFO ][transport                ] [Goblin Queen] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:25:29,000][INFO ][discovery                ] [Goblin Queen] elasticsearch/63twAGMPQ0KJKLeHBMC38A
[2017-08-22 11:25:32,030][INFO ][cluster.service          ] [Goblin Queen] new_master {Goblin Queen}{63twAGMPQ0KJKLeHBMC38A}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:25:32,048][INFO ][http                     ] [Goblin Queen] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:25:32,048][INFO ][node                     ] [Goblin Queen] started
[2017-08-22 11:25:32,061][INFO ][gateway                  ] [Goblin Queen] recovered [0] indices into cluster_state
[2017-08-22 11:25:38,243][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 11:25:38,243][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 11:25:38,246][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 11:25:38,293][DEBUG][action.admin.indices.create] [Goblin Queen] [guruin_dev] failed to create
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:25:38,296][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:28:23,331][DEBUG][action.admin.indices.create] [Goblin Queen] [guruin_dev] failed to create
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:28:23,332][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
MapperParsingException[mapping [gurus]]; nested: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]];
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:371)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: MapperParsingException[analyzer [ik_smart_pinyin] not found for field [nickname_searchable]]
	at org.elasticsearch.index.mapper.core.TypeParsers.parseField(TypeParsers.java:259)
	at org.elasticsearch.index.mapper.core.StringFieldMapper$TypeParser.parse(StringFieldMapper.java:161)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:315)
	at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:228)
	at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:137)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:211)
	at org.elasticsearch.index.mapper.DocumentMapperParser.parseCompressed(DocumentMapperParser.java:192)
	at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:368)
	at org.elasticsearch.index.mapper.MapperService.merge(MapperService.java:242)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:368)
	... 6 more
[2017-08-22 11:29:40,942][INFO ][node                     ] [Goblin Queen] stopping ...
[2017-08-22 11:29:40,953][INFO ][node                     ] [Goblin Queen] stopped
[2017-08-22 11:29:40,953][INFO ][node                     ] [Goblin Queen] closing ...
[2017-08-22 11:29:40,956][INFO ][node                     ] [Goblin Queen] closed
[2017-08-22 11:31:16,157][INFO ][node                     ] [Purple Man] version[2.0.0], pid[21585], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:31:16,158][INFO ][node                     ] [Purple Man] initializing ...
[2017-08-22 11:31:16,314][INFO ][plugins                  ] [Purple Man] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 11:31:16,342][INFO ][env                      ] [Purple Man] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:31:17,527][INFO ][node                     ] [Purple Man] initialized
[2017-08-22 11:31:17,527][INFO ][node                     ] [Purple Man] starting ...
[2017-08-22 11:31:17,616][INFO ][transport                ] [Purple Man] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:31:17,623][INFO ][discovery                ] [Purple Man] elasticsearch/MzdcXXaIQIOLY2NAMi59nA
[2017-08-22 11:31:20,650][INFO ][cluster.service          ] [Purple Man] new_master {Purple Man}{MzdcXXaIQIOLY2NAMi59nA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:31:20,669][INFO ][http                     ] [Purple Man] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:31:20,669][INFO ][node                     ] [Purple Man] started
[2017-08-22 11:31:20,681][INFO ][gateway                  ] [Purple Man] recovered [0] indices into cluster_state
[2017-08-22 11:31:21,541][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 11:31:21,541][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 11:31:21,543][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 11:31:21,724][INFO ][cluster.metadata         ] [Purple Man] [guruin_dev] creating index, cause [api], templates [], shards [1]/[0], mappings [gurus, keywords, questions, landing_pages, groups, listings, coupons, activities, article_collections, fresh_stories, feeds, attractions, merchant_collections, merchants, articles, pois]
[2017-08-22 11:31:50,730][INFO ][cluster.metadata         ] [Purple Man] [guruin_dev] update_mapping [feeds]
[2017-08-22 11:34:25,317][INFO ][node                     ] [Purple Man] stopping ...
[2017-08-22 11:34:25,349][INFO ][node                     ] [Purple Man] stopped
[2017-08-22 11:34:25,350][INFO ][node                     ] [Purple Man] closing ...
[2017-08-22 11:34:25,354][INFO ][node                     ] [Purple Man] closed
[2017-08-22 11:34:43,163][INFO ][node                     ] [Doug Ramsey] version[2.0.0], pid[21715], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:34:43,163][INFO ][node                     ] [Doug Ramsey] initializing ...
[2017-08-22 11:34:43,368][INFO ][plugins                  ] [Doug Ramsey] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 11:34:43,398][INFO ][env                      ] [Doug Ramsey] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:34:44,926][INFO ][node                     ] [Doug Ramsey] initialized
[2017-08-22 11:34:44,926][INFO ][node                     ] [Doug Ramsey] starting ...
[2017-08-22 11:34:45,020][INFO ][transport                ] [Doug Ramsey] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:34:45,031][INFO ][discovery                ] [Doug Ramsey] elasticsearch/21xZ8mXXRr-U6MdUTmDNxg
[2017-08-22 11:34:48,068][INFO ][cluster.service          ] [Doug Ramsey] new_master {Doug Ramsey}{21xZ8mXXRr-U6MdUTmDNxg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:34:48,095][INFO ][http                     ] [Doug Ramsey] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:34:48,095][INFO ][node                     ] [Doug Ramsey] started
[2017-08-22 11:34:48,131][INFO ][gateway                  ] [Doug Ramsey] recovered [1] indices into cluster_state
[2017-08-22 11:34:48,480][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 11:34:48,481][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 11:34:48,483][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 11:34:54,957][INFO ][node                     ] [Doug Ramsey] stopping ...
[2017-08-22 11:34:55,017][INFO ][node                     ] [Doug Ramsey] stopped
[2017-08-22 11:34:55,018][INFO ][node                     ] [Doug Ramsey] closing ...
[2017-08-22 11:34:55,021][INFO ][node                     ] [Doug Ramsey] closed
[2017-08-22 11:35:10,990][INFO ][node                     ] [Electron] version[2.0.0], pid[21757], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 11:35:10,991][INFO ][node                     ] [Electron] initializing ...
[2017-08-22 11:35:11,157][INFO ][plugins                  ] [Electron] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 11:35:11,183][INFO ][env                      ] [Electron] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 11:35:12,444][INFO ][node                     ] [Electron] initialized
[2017-08-22 11:35:12,444][INFO ][node                     ] [Electron] starting ...
[2017-08-22 11:35:12,528][INFO ][transport                ] [Electron] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 11:35:12,535][INFO ][discovery                ] [Electron] elasticsearch/nxhzOhxtRGCwSCm6dWa82A
[2017-08-22 11:35:15,567][INFO ][cluster.service          ] [Electron] new_master {Electron}{nxhzOhxtRGCwSCm6dWa82A}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 11:35:15,591][INFO ][http                     ] [Electron] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 11:35:15,592][INFO ][node                     ] [Electron] started
[2017-08-22 11:35:15,623][INFO ][gateway                  ] [Electron] recovered [1] indices into cluster_state
[2017-08-22 11:35:15,961][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 11:35:15,961][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 11:35:15,963][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 11:37:59,568][INFO ][node                     ] [Electron] stopping ...
[2017-08-22 11:37:59,594][INFO ][node                     ] [Electron] stopped
[2017-08-22 11:37:59,594][INFO ][node                     ] [Electron] closing ...
[2017-08-22 11:37:59,597][INFO ][node                     ] [Electron] closed
[2017-08-22 12:06:17,956][INFO ][node                     ] [Franklin Storm] version[2.0.0], pid[23321], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 12:06:17,956][INFO ][node                     ] [Franklin Storm] initializing ...
[2017-08-22 12:06:18,124][INFO ][plugins                  ] [Franklin Storm] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 12:06:18,153][INFO ][env                      ] [Franklin Storm] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [104.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2017-08-22 12:06:19,460][INFO ][node                     ] [Franklin Storm] initialized
[2017-08-22 12:06:19,460][INFO ][node                     ] [Franklin Storm] starting ...
[2017-08-22 12:06:19,548][INFO ][transport                ] [Franklin Storm] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 12:06:19,554][INFO ][discovery                ] [Franklin Storm] elasticsearch/W084AXLgRGCnIYKIAttFlw
[2017-08-22 12:06:22,581][INFO ][cluster.service          ] [Franklin Storm] new_master {Franklin Storm}{W084AXLgRGCnIYKIAttFlw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 12:06:22,606][INFO ][http                     ] [Franklin Storm] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 12:06:22,607][INFO ][node                     ] [Franklin Storm] started
[2017-08-22 12:06:22,642][INFO ][gateway                  ] [Franklin Storm] recovered [1] indices into cluster_state
[2017-08-22 12:06:23,004][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 12:06:23,004][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 12:06:23,006][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 12:07:32,335][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [activities]
[2017-08-22 12:07:32,355][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [activities]
[2017-08-22 12:07:32,916][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [activities]
[2017-08-22 12:59:57,025][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [article_collections]
[2017-08-22 13:15:24,715][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [attractions]
[2017-08-22 13:15:24,724][INFO ][cluster.metadata         ] [Franklin Storm] [guruin_dev] update_mapping [attractions]
[2017-08-22 14:02:03,930][INFO ][node                     ] [Brass] version[2.0.0], pid[20724], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 14:02:03,930][INFO ][node                     ] [Brass] initializing ...
[2017-08-22 14:02:04,151][INFO ][plugins                  ] [Brass] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 14:02:04,195][INFO ][env                      ] [Brass] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [56gb], net total_space [232.6gb], spins? [unknown], types [hfs]
[2017-08-22 14:02:06,116][INFO ][node                     ] [Brass] initialized
[2017-08-22 14:02:06,116][INFO ][node                     ] [Brass] starting ...
[2017-08-22 14:02:06,205][INFO ][transport                ] [Brass] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 14:02:06,212][INFO ][discovery                ] [Brass] elasticsearch/ZAYHrFydTH6Fad7mLxrbrw
[2017-08-22 14:02:09,248][INFO ][cluster.service          ] [Brass] new_master {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 14:02:09,299][INFO ][http                     ] [Brass] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 14:02:09,300][INFO ][node                     ] [Brass] started
[2017-08-22 14:02:09,345][INFO ][gateway                  ] [Brass] recovered [1] indices into cluster_state
[2017-08-22 14:02:09,953][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 14:02:09,954][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 14:02:09,965][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 14:02:24,706][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:02:24,710][INFO ][rest.suppressed          ] /guruin_dev/merchants/_search Params: {size=10, index=guruin_dev, from=0, type=merchants}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:02:44,933][WARN ][indices.cluster          ] [Brass] [[guruin_dev][0]] marking and sending shard failed due to [failed recovery]
[guruin_dev][[guruin_dev][0]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to recover from translog]; nested: EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:258)
	at org.elasticsearch.index.shard.StoreRecoveryService.access$100(StoreRecoveryService.java:60)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [guruin_dev][[guruin_dev][0]] EngineCreationFailureException[failed to recover from translog]; nested: EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157)
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25)
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1349)
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1344)
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:889)
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:866)
	at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:249)
	... 5 more
Caused by: [guruin_dev][[guruin_dev][0]] EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:233)
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:154)
	... 11 more
Caused by: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.translog.TranslogReader.readSize(TranslogReader.java:102)
	at org.elasticsearch.index.translog.TranslogReader.access$000(TranslogReader.java:46)
	at org.elasticsearch.index.translog.TranslogReader$ReaderSnapshot.readOperation(TranslogReader.java:297)
	at org.elasticsearch.index.translog.TranslogReader$ReaderSnapshot.next(TranslogReader.java:290)
	at org.elasticsearch.index.translog.MultiSnapshot.next(MultiSnapshot.java:70)
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:219)
	... 12 more
Caused by: java.io.EOFException: read past EOF. pos [71240928] length: [4] end: [71240928]
	at org.elasticsearch.common.io.Channels.readFromFileChannelWithEofException(Channels.java:102)
	at org.elasticsearch.index.translog.ImmutableTranslogReader.readBytes(ImmutableTranslogReader.java:84)
	at org.elasticsearch.index.translog.TranslogReader.readSize(TranslogReader.java:91)
	... 17 more
[2017-08-22 14:02:44,937][WARN ][cluster.action.shard     ] [Brass] [guruin_dev][0] received shard failed for [guruin_dev][0], node[ZAYHrFydTH6Fad7mLxrbrw], [P], v[9], s[INITIALIZING], a[id=0RwR6t75Qm6Q0ryjsCaCIg], unassigned_info[[reason=CLUSTER_RECOVERED], at[2017-08-22T06:02:09.284Z]], indexUUID [ilZpSSs2SViwB4qNIkejeQ], message [failed recovery], failure [IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to recover from translog]; nested: EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]]; ]
[guruin_dev][[guruin_dev][0]] IndexShardRecoveryException[failed to recovery from gateway]; nested: EngineCreationFailureException[failed to recover from translog]; nested: EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:258)
	at org.elasticsearch.index.shard.StoreRecoveryService.access$100(StoreRecoveryService.java:60)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: [guruin_dev][[guruin_dev][0]] EngineCreationFailureException[failed to recover from translog]; nested: EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157)
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25)
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1349)
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1344)
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:889)
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:866)
	at org.elasticsearch.index.shard.StoreRecoveryService.recoverFromStore(StoreRecoveryService.java:249)
	... 5 more
Caused by: [guruin_dev][[guruin_dev][0]] EngineException[failed to recover from translog]; nested: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:233)
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:154)
	... 11 more
Caused by: ElasticsearchException[unexpected exception reading from translog snapshot of /Users/mac-gaogao/github/elasticsearch/data/elasticsearch/nodes/0/indices/guruin_dev/0/translog/translog-7.tlog]; nested: EOFException[read past EOF. pos [71240928] length: [4] end: [71240928]];
	at org.elasticsearch.index.translog.TranslogReader.readSize(TranslogReader.java:102)
	at org.elasticsearch.index.translog.TranslogReader.access$000(TranslogReader.java:46)
	at org.elasticsearch.index.translog.TranslogReader$ReaderSnapshot.readOperation(TranslogReader.java:297)
	at org.elasticsearch.index.translog.TranslogReader$ReaderSnapshot.next(TranslogReader.java:290)
	at org.elasticsearch.index.translog.MultiSnapshot.next(MultiSnapshot.java:70)
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:219)
	... 12 more
Caused by: java.io.EOFException: read past EOF. pos [71240928] length: [4] end: [71240928]
	at org.elasticsearch.common.io.Channels.readFromFileChannelWithEofException(Channels.java:102)
	at org.elasticsearch.index.translog.ImmutableTranslogReader.readBytes(ImmutableTranslogReader.java:84)
	at org.elasticsearch.index.translog.TranslogReader.readSize(TranslogReader.java:91)
	... 17 more
[2017-08-22 14:03:02,470][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:02,475][INFO ][rest.suppressed          ] /guruin_dev/merchants/_search Params: {size=10, index=guruin_dev, from=0, type=merchants}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,401][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,408][INFO ][rest.suppressed          ] /guruin_dev/fresh_stories/_search Params: {size=8, index=guruin_dev, from=0, type=fresh_stories}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,429][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,439][INFO ][rest.suppressed          ] /guruin_dev/feeds/_search Params: {size=10, index=guruin_dev, from=0, type=feeds}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,460][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,466][INFO ][rest.suppressed          ] /guruin_dev/activities/_search Params: {size=6, index=guruin_dev, from=0, type=activities}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,486][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,497][INFO ][rest.suppressed          ] /guruin_dev/activities/_search Params: {size=6, index=guruin_dev, from=0, type=activities}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,512][DEBUG][action.search.type       ] [Brass] All shards failed for phase: [query_fetch]
RemoteTransportException[[Brass][127.0.0.1:9300][indices:data/read/search[phase/query+fetch]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [guruin_dev][[guruin_dev][0]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:957)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:791)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:655)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:632)
	at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:465)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:392)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchTransportHandler.messageReceived(SearchServiceTransportAction.java:389)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:10,519][INFO ][rest.suppressed          ] /guruin_dev/merchants/_search Params: {size=8, index=guruin_dev, from=0, type=merchants}
Failed to execute phase [query_fetch], all shards failed
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:14,492][INFO ][node                     ] [Brass] stopping ...
[2017-08-22 14:03:14,500][INFO ][rest.suppressed          ] /guruin_dev/merchants/552 Params: {index=guruin_dev, id=552, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,502][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,503][INFO ][rest.suppressed          ] /guruin_dev/merchants/555 Params: {index=guruin_dev, id=555, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,504][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,505][INFO ][rest.suppressed          ] /guruin_dev/merchants/553 Params: {index=guruin_dev, id=553, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,506][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,508][INFO ][rest.suppressed          ] /guruin_dev/merchants/554 Params: {index=guruin_dev, id=554, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,508][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,510][INFO ][rest.suppressed          ] /guruin_dev/merchants/556 Params: {index=guruin_dev, id=556, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,511][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,512][INFO ][rest.suppressed          ] /guruin_dev/merchants/557 Params: {index=guruin_dev, id=557, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,513][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,515][INFO ][rest.suppressed          ] /guruin_dev/merchants/558 Params: {index=guruin_dev, id=558, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,516][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,518][INFO ][rest.suppressed          ] /guruin_dev/merchants/559 Params: {index=guruin_dev, id=559, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,518][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,520][INFO ][rest.suppressed          ] /guruin_dev/merchants/560 Params: {index=guruin_dev, id=560, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,521][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,522][INFO ][rest.suppressed          ] /guruin_dev/merchants/561 Params: {index=guruin_dev, id=561, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,522][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,524][INFO ][rest.suppressed          ] /guruin_dev/merchants/562 Params: {index=guruin_dev, id=562, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,524][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,525][INFO ][rest.suppressed          ] /guruin_dev/merchants/563 Params: {index=guruin_dev, id=563, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,526][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,527][INFO ][rest.suppressed          ] /guruin_dev/merchants/564 Params: {index=guruin_dev, id=564, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,528][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,529][INFO ][rest.suppressed          ] /guruin_dev/merchants/565 Params: {index=guruin_dev, id=565, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,530][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,532][INFO ][rest.suppressed          ] /guruin_dev/merchants/566 Params: {index=guruin_dev, id=566, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,533][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,534][INFO ][rest.suppressed          ] /guruin_dev/merchants/569 Params: {index=guruin_dev, id=569, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,534][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,536][INFO ][rest.suppressed          ] /guruin_dev/merchants/567 Params: {index=guruin_dev, id=567, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,537][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,539][INFO ][rest.suppressed          ] /guruin_dev/merchants/568 Params: {index=guruin_dev, id=568, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,541][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,545][INFO ][rest.suppressed          ] /guruin_dev/merchants/570 Params: {index=guruin_dev, id=570, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,546][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,547][INFO ][rest.suppressed          ] /guruin_dev/merchants/571 Params: {index=guruin_dev, id=571, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,549][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,552][INFO ][rest.suppressed          ] /guruin_dev/merchants/572 Params: {index=guruin_dev, id=572, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,553][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,555][INFO ][rest.suppressed          ] /guruin_dev/merchants/573 Params: {index=guruin_dev, id=573, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,555][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,557][INFO ][rest.suppressed          ] /guruin_dev/merchants/574 Params: {index=guruin_dev, id=574, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,558][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,560][INFO ][rest.suppressed          ] /guruin_dev/merchants/575 Params: {index=guruin_dev, id=575, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,562][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,568][INFO ][rest.suppressed          ] /guruin_dev/merchants/576 Params: {index=guruin_dev, id=576, type=merchants}
NodeClosedException[node closed {Brass}{ZAYHrFydTH6Fad7mLxrbrw}{127.0.0.1}{127.0.0.1:9300}]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:14,569][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.jboss.netty.channel.Channels.write(Channels.java:725)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:174)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.finishAsFailed(TransportReplicationAction.java:541)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase$3.onClusterServiceClose(TransportReplicationAction.java:514)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:225)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:176)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:88)
	at org.elasticsearch.node.Node.stop(Node.java:298)
	at org.elasticsearch.node.Node.close(Node.java:323)
	at org.elasticsearch.bootstrap.Bootstrap$4.run(Bootstrap.java:149)
[2017-08-22 14:03:17,140][INFO ][node                     ] [Brass] stopped
[2017-08-22 14:03:17,141][INFO ][node                     ] [Brass] closing ...
[2017-08-22 14:03:17,145][INFO ][node                     ] [Brass] closed
[2017-08-22 14:03:26,795][INFO ][node                     ] [Modred the Mystic] version[2.0.0], pid[21486], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 14:03:26,796][INFO ][node                     ] [Modred the Mystic] initializing ...
[2017-08-22 14:03:27,065][INFO ][plugins                  ] [Modred the Mystic] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 14:03:27,112][INFO ][env                      ] [Modred the Mystic] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [56gb], net total_space [232.6gb], spins? [unknown], types [hfs]
[2017-08-22 14:03:29,066][INFO ][node                     ] [Modred the Mystic] initialized
[2017-08-22 14:03:29,066][INFO ][node                     ] [Modred the Mystic] starting ...
[2017-08-22 14:03:29,157][INFO ][transport                ] [Modred the Mystic] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 14:03:29,170][INFO ][discovery                ] [Modred the Mystic] elasticsearch/TRn9Y8tWRfW7kxWRAX8ydg
[2017-08-22 14:03:32,206][INFO ][cluster.service          ] [Modred the Mystic] new_master {Modred the Mystic}{TRn9Y8tWRfW7kxWRAX8ydg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 14:03:32,237][INFO ][http                     ] [Modred the Mystic] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 14:03:32,237][INFO ][node                     ] [Modred the Mystic] started
[2017-08-22 14:03:32,270][INFO ][gateway                  ] [Modred the Mystic] recovered [1] indices into cluster_state
[2017-08-22 14:03:32,823][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 14:03:32,831][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 14:03:32,842][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 14:03:33,457][INFO ][rest.suppressed          ] / Params: {}
org.elasticsearch.action.ActionRequestValidationException: Validation Failed: 1: index / indices is missing;
	at org.elasticsearch.action.ValidateActions.addValidationError(ValidateActions.java:29)
	at org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest.validate(DeleteIndexRequest.java:82)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:62)
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:58)
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:347)
	at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:52)
	at org.elasticsearch.rest.BaseRestHandler$HeadersAndContextCopyClient.doExecute(BaseRestHandler.java:83)
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:347)
	at org.elasticsearch.client.support.AbstractClient$IndicesAdmin.execute(AbstractClient.java:1177)
	at org.elasticsearch.client.support.AbstractClient$IndicesAdmin.delete(AbstractClient.java:1317)
	at org.elasticsearch.rest.action.admin.indices.delete.RestDeleteIndexAction.handleRequest(RestDeleteIndexAction.java:50)
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54)
	at org.elasticsearch.rest.RestController.executeHandler(RestController.java:207)
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:166)
	at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:128)
	at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:86)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:348)
	at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:63)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:03:39,997][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] deleting index
[2017-08-22 14:05:03,731][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] creating index, cause [auto(index api)], templates [], shards [5]/[1], mappings [merchants]
[2017-08-22 14:05:03,851][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:03,894][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:04,588][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:26,356][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:26,464][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:26,633][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:05:44,526][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][2], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=90lG4yVvRt-AI6fQa41vaw]: Failed to execute [org.elasticsearch.action.search.SearchRequest@207f7010] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,526][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][1], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=2ImlcAW5TmqgKfghUqXxOA]: Failed to execute [org.elasticsearch.action.search.SearchRequest@207f7010] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,526][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][0], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=7b_1ov-VT0-H0IRP8OqIfQ]: Failed to execute [org.elasticsearch.action.search.SearchRequest@207f7010] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,529][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][4], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=oN9dcvF4QyyHOYL087KYuA]: Failed to execute [org.elasticsearch.action.search.SearchRequest@207f7010]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,528][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][3], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=fPlc9KT9S-6y-P17rvtXBg]: Failed to execute [org.elasticsearch.action.search.SearchRequest@207f7010] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,530][DEBUG][action.search.type       ] [Modred the Mystic] All shards failed for phase: [query]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:05:44,533][INFO ][rest.suppressed          ] /guruin_dev/merchants/_search Params: {size=10, index=guruin_dev, from=0, type=merchants}
Failed to execute phase [query], all shards failed; shardFailures {[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][0]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][1]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][2]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][3]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][4]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2017-08-22 14:06:32,222][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][4], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=oN9dcvF4QyyHOYL087KYuA]: Failed to execute [org.elasticsearch.action.search.SearchRequest@5b4870ee] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:06:32,222][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][0], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=7b_1ov-VT0-H0IRP8OqIfQ]: Failed to execute [org.elasticsearch.action.search.SearchRequest@5b4870ee] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:06:32,223][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][3], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=fPlc9KT9S-6y-P17rvtXBg]: Failed to execute [org.elasticsearch.action.search.SearchRequest@5b4870ee]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:06:32,234][DEBUG][action.search.type       ] [Modred the Mystic] All shards failed for phase: [query]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:06:32,235][INFO ][rest.suppressed          ] /guruin_dev/merchants/_search Params: {size=10, index=guruin_dev, from=0, type=merchants}
Failed to execute phase [query], all shards failed; shardFailures {[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][0]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][1]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][2]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][3]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }{[TRn9Y8tWRfW7kxWRAX8ydg][guruin_dev][4]: RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested]; }
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:228)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:174)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:821)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:799)
	at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:361)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2017-08-22 14:06:32,223][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][2], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=90lG4yVvRt-AI6fQa41vaw]: Failed to execute [org.elasticsearch.action.search.SearchRequest@5b4870ee] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:06:32,222][DEBUG][action.search.type       ] [Modred the Mystic] [guruin_dev][1], node[TRn9Y8tWRfW7kxWRAX8ydg], [P], v[2], s[STARTED], a[id=2ImlcAW5TmqgKfghUqXxOA]: Failed to execute [org.elasticsearch.action.search.SearchRequest@5b4870ee] lastShard [true]
RemoteTransportException[[Modred the Mystic][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: AggregationExecutionException[[nested] nested path [categories] is not nested];
Caused by: AggregationExecutionException[[nested] nested path [categories] is not nested]
	at org.elasticsearch.search.aggregations.bucket.nested.NestedAggregator$Factory.createInternal(NestedAggregator.java:164)
	at org.elasticsearch.search.aggregations.AggregatorFactory.create(AggregatorFactory.java:102)
	at org.elasticsearch.search.aggregations.AggregatorFactories.createTopLevelAggregators(AggregatorFactories.java:87)
	at org.elasticsearch.search.aggregations.AggregationPhase.preProcess(AggregationPhase.java:79)
	at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:96)
	at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:369)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:381)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
	at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:07:28,064][INFO ][cluster.metadata         ] [Modred the Mystic] [guruin_dev] deleting index
[2017-08-22 14:07:30,989][INFO ][node                     ] [Modred the Mystic] stopping ...
[2017-08-22 14:07:30,999][INFO ][node                     ] [Modred the Mystic] stopped
[2017-08-22 14:07:30,999][INFO ][node                     ] [Modred the Mystic] closing ...
[2017-08-22 14:07:31,003][INFO ][node                     ] [Modred the Mystic] closed
[2017-08-22 14:07:32,717][INFO ][node                     ] [Amatsu-Mikaboshi] version[2.0.0], pid[23852], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 14:07:32,717][INFO ][node                     ] [Amatsu-Mikaboshi] initializing ...
[2017-08-22 14:07:32,998][INFO ][plugins                  ] [Amatsu-Mikaboshi] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 14:07:33,042][INFO ][env                      ] [Amatsu-Mikaboshi] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [56.3gb], net total_space [232.6gb], spins? [unknown], types [hfs]
[2017-08-22 14:07:35,005][INFO ][node                     ] [Amatsu-Mikaboshi] initialized
[2017-08-22 14:07:35,005][INFO ][node                     ] [Amatsu-Mikaboshi] starting ...
[2017-08-22 14:07:35,085][INFO ][transport                ] [Amatsu-Mikaboshi] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 14:07:35,092][INFO ][discovery                ] [Amatsu-Mikaboshi] elasticsearch/l1VFJ3reSD22aa6efPSGZA
[2017-08-22 14:07:38,125][INFO ][cluster.service          ] [Amatsu-Mikaboshi] new_master {Amatsu-Mikaboshi}{l1VFJ3reSD22aa6efPSGZA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 14:07:38,150][INFO ][http                     ] [Amatsu-Mikaboshi] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 14:07:38,150][INFO ][node                     ] [Amatsu-Mikaboshi] started
[2017-08-22 14:07:38,163][INFO ][gateway                  ] [Amatsu-Mikaboshi] recovered [0] indices into cluster_state
[2017-08-22 14:07:38,925][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 14:07:38,926][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 14:07:38,933][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 14:07:39,284][INFO ][cluster.metadata         ] [Amatsu-Mikaboshi] [guruin_dev] creating index, cause [api], templates [], shards [1]/[0], mappings [gurus, keywords, questions, landing_pages, groups, listings, coupons, activities, article_collections, fresh_stories, feeds, attractions, merchant_collections, merchants, articles, pois]
[2017-08-22 14:07:40,492][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
[guruin_dev] IndexAlreadyExistsException[already exists]
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:161)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:512)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:90)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:231)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:07:42,339][INFO ][rest.suppressed          ] /guruin_dev Params: {index=guruin_dev}
[guruin_dev] IndexAlreadyExistsException[already exists]
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:161)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:512)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:90)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:231)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:388)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:225)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-22 14:08:14,072][INFO ][cluster.metadata         ] [Amatsu-Mikaboshi] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:08:15,379][INFO ][cluster.metadata         ] [Amatsu-Mikaboshi] [guruin_dev] update_mapping [merchants]
[2017-08-22 14:09:18,625][INFO ][node                     ] [Amatsu-Mikaboshi] stopping ...
[2017-08-22 14:09:18,670][INFO ][node                     ] [Amatsu-Mikaboshi] stopped
[2017-08-22 14:09:18,670][INFO ][node                     ] [Amatsu-Mikaboshi] closing ...
[2017-08-22 14:09:18,674][INFO ][node                     ] [Amatsu-Mikaboshi] closed
[2017-08-22 14:11:32,200][INFO ][node                     ] [Solarman] version[2.0.0], pid[26582], build[de54438/2015-10-22T08:09:48Z]
[2017-08-22 14:11:32,201][INFO ][node                     ] [Solarman] initializing ...
[2017-08-22 14:11:32,391][INFO ][plugins                  ] [Solarman] loaded [analysis-pinyin, analysis-ik], sites []
[2017-08-22 14:11:32,421][INFO ][env                      ] [Solarman] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [56.3gb], net total_space [232.6gb], spins? [unknown], types [hfs]
[2017-08-22 14:11:34,078][INFO ][node                     ] [Solarman] initialized
[2017-08-22 14:11:34,079][INFO ][node                     ] [Solarman] starting ...
[2017-08-22 14:11:34,196][INFO ][transport                ] [Solarman] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[fe80::1]:9300}, {[::1]:9300}
[2017-08-22 14:11:34,207][INFO ][discovery                ] [Solarman] elasticsearch/znhvrXyZRsKfsWWt_QPF2g
[2017-08-22 14:11:37,251][INFO ][cluster.service          ] [Solarman] new_master {Solarman}{znhvrXyZRsKfsWWt_QPF2g}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-08-22 14:11:37,280][INFO ][http                     ] [Solarman] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[fe80::1]:9200}, {[::1]:9200}
[2017-08-22 14:11:37,280][INFO ][node                     ] [Solarman] started
[2017-08-22 14:11:37,306][INFO ][gateway                  ] [Solarman] recovered [1] indices into cluster_state
[2017-08-22 14:11:37,904][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-08-22 14:11:37,904][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-08-22 14:11:37,910][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-08-22 14:11:38,445][INFO ][cluster.metadata         ] [Solarman] [guruin_dev] deleting index
[2017-08-22 14:11:40,470][INFO ][node                     ] [Solarman] stopping ...
[2017-08-22 14:11:40,480][INFO ][node                     ] [Solarman] stopped
[2017-08-22 14:11:40,481][INFO ][node                     ] [Solarman] closing ...
[2017-08-22 14:11:40,536][INFO ][node                     ] [Solarman] closed
